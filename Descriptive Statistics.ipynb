{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot\n",
    "* Provides case by case view of data for two numerical variables. Each point represents single case. Useful to spot association between variables.\n",
    "\n",
    "### Dot plots\n",
    "* Most basic display for one variable analysis. It is called one variable scatter plot.\n",
    "* Shows exact values for each observation.\n",
    "* Can get busy as sample size increases.\n",
    "![dot plot](images/dot_plot.JPG)\n",
    "\n",
    "### Histograms\n",
    "* Dot plot is good for small dataset, in larger dataset we can assign observation to bin. Provides view of data density. Higher bar means more common data.\n",
    "* Also describe the shape of the data distribution. Right skewed: long thin tail to the right, left skewed: long thin tail to the left, symmetric: equal trailing in both directions.\n",
    "![skewness](images/skewness.JPG)\n",
    "* We can identify mode using histogram.\n",
    "* Histogram can be unimodal(1 prominent peak), bimodal(2 prominent peak) or multimodal(more than 2 prominent peak).\n",
    "![modality](images/modal.JPG)\n",
    "* Bin width can alter story of histogram, Wide bin, loose interesting details. Narrow bin will difficult to get overall picture. Also, get discontinuity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure of center\n",
    "### Mean, Average, Arithmatic mean\n",
    "* Sum of the all observation divided by number of observations.\n",
    "* Sample mean is shown as $\\bar{x}$. Population mean is shown as $\\mu$\n",
    "* Mean is located where total distance of value below mean = total distance of value above the mean.\n",
    "\n",
    "### Weighted mean\n",
    "* Influence more by some observation than others. We assign weights to observation based on its importance.\n",
    "\n",
    "$$ weighted\\ mean = \\frac{w_1x_1 + w_2x_2 + w_3x_3 + ... + w_nx_n}{w_1 + w_2 + w_3 + ... + w_n}$$\n",
    "* Simple mean is just special case of weight mean in which weight of all w's is 1.\n",
    "\n",
    "```\n",
    "np.average(lst, weights = lst)\n",
    "```\n",
    "### Mode\n",
    "* Most frequent observation.\n",
    "\n",
    "### Median\n",
    "* Mid point of distribution or 50th percentile.\n",
    "* If the data is ordered from smaller to larger, mid element is median. If there are even number of elements, median is mean of middle two elements.\n",
    "* In left skewed distribution mean is lower than median. As lower values pull mean toward them\n",
    "* In right skewed distribution mean is larger than median. As larger value pull the mean toward them.\n",
    "![skewness_mean_median](images/skewness_mean_median.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure of Spread\n",
    "* How far away typical observation from mean. Distance of an observation from mean is called deviation.\n",
    "\n",
    "### Range\n",
    "* Difference of min and max value\n",
    "\n",
    "### Variance\n",
    "* Average squared distance from mean.\n",
    "* Square of the deviation and taking its average. Sample variance denoted by $s^2$. Population variance is $\\sigma^2$\n",
    "* Squaring the deviation does two things makes large value larger and get rid of negative sign so positive and negative does not cancel each other out.\n",
    "\n",
    "$$s^2 = \\frac{\\sum^n_{i=1}(x_i - \\bar{x})^2}{n-1}$$\n",
    "\n",
    "### Standard deviation\n",
    "* Square root of variance.\n",
    "* It has the same unit as observed data.\n",
    "* Useful to check how close the data are from mean.\n",
    "* Sample standard deviation is denoted by $s$. Population standard deviation is $\\sigma$.\n",
    "$$\\sigma^2 = \\sqrt{\\frac{\\sum^n_{i=1}(x_i - \\bar{x})^2}{n-1}}$$\n",
    "\n",
    "#### n-1 vs n in sample and population (Bessel's correction)\n",
    "* The standard deviation calculated with a divisor of n−1 is a standard deviation calculated from the sample as an estimate of the standard deviation of the population from which the sample was drawn. Because the observed values fall, on average, closer to the sample mean than to the population mean, the standard deviation which is calculated using deviations from the sample mean underestimates the desired standard deviation of the population. Using n−1 instead of n as the divisor corrects for that by making the result a little bit bigger.\n",
    "* Note that the correction has a larger proportional effect when n is small than when it is large, which is what we want because when n is larger the sample mean is likely to be a good estimator of the population mean.\n",
    "* When the sample is the whole population we use the standard deviation with n as the divisor because the sample mean is population mean.\n",
    "* When we sample from population spread of sample is lower, so sample standard distribution under estimate population standard deviation\n",
    "```\n",
    "pd.std() or np.std()\n",
    "# we have ddof parameter in both functions, which is default to 1 always, to find population std set it to 0.\n",
    "```\n",
    "\n",
    "### Interquartile range\n",
    "* Range of middle 50% of data.\n",
    "* Distance between first quartile and 3rd quartile.\n",
    "$$IQR = Q3 - Q1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variance of tow different random variable = sum of there individual variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plots\n",
    "* Summarize dataset using 5 statistics, Q1, median, min, max, Q3. Also plot unusual observations(outlier).\n",
    "![box plot](images/box_plot.JPG)\n",
    "* more variable data larger the SD and IQR.\n",
    "* Whiskers attempts to capture data out of the box, but they are never allowed to be more than  `1.5 * IQR` So upper whisker does not extend beyond `Q3 + 1.5*IQR`  and does not extend down to `Q1 - 1.5*IQR`. Observation beyond the whisker are noted with dot. Such observation are outliers in general.\n",
    "![box plot and skewness](images/box_plot_skewness.JPG)\n",
    "* Examining outliers provide, identification of strong skew in distribution, Data entry errors or collections error, Provide insight to interesting properties of data.\n",
    "\n",
    "\n",
    "### Intensity map\n",
    "* Geographical data usually mapped in intensity map. \n",
    "* Colors used to show higher and lower value of variable.\n",
    "* Usually good for checking geographic trend.\n",
    "![intensity map](images/intensity_map.JPG)\n",
    "\n",
    "### Showing categorical variable\n",
    "#### Frequency table\n",
    "* Table of single variable is called frequency table. When we consider percentage or proportion instead count it is relative frequency table.\n",
    "![frequency table](images/frequency_table.JPG)\n",
    "\n",
    "#### Bar plot\n",
    "* Common way to plot single categorical variable.\n",
    "![bar_plot](images/bar_plot.JPG)\n",
    "* Histogram vs bar-chart\n",
    "    - Bar plot is for categorical, histogram for numerical\n",
    "    - x-axis on histogram is number line, ordering of bar can not be changed. In bar plot order of bar can be changed.\n",
    "    \n",
    "#### Pie chart\n",
    "![pie chart](images/pie_chart.JPG)\n",
    "\n",
    "#### Contingency table\n",
    "* Table that summarizes data for 2 categorical variables. Each value is table shows number of time each particular combination of variable outcome occurs.\n",
    "![contingency_table](images/contingency_table.JPG)\n",
    "\n",
    "#### Segmented bar plot\n",
    "* Graphical display for information of contingency table.\n",
    "![segmented bar](images/segmented_bar.JPG)\n",
    "![segmented bar relative](images/segmented_bar_relative.JPG)\n",
    "\n",
    "#### Mosaic plot\n",
    "![mosaic plot](images/mosaic_plot.JPG)\n",
    "* column width also represents marginal distribution.\n",
    "\n",
    "#### Side by side box plot\n",
    "* Compare numerical and categorical variable\n",
    "* Useful to compare numerical variable across the groups.\n",
    "![side by side plot](images/side_by_side.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust statistics\n",
    "* If extreme observation has little effect such statistics is called robust statistics.\n",
    "* median and IQR are robust to extreme observations.\n",
    "* mean and SD, range is not robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Density Estimation\n",
    "* One way to estimate probability density function, each observation is represented as small lump of area, stacking such lump is final density curve. Vertical axis represent density of data. Probability between 2 values is area between those.\n",
    "* When sample size is small, in histogram data has jumps, KDE provides smooth estimates of overall data.\n",
    "* We can also make inference about population from finite sample using kde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection methods\n",
    "\n",
    "#### SD method\n",
    "* 2 SD method or 3 SD method, observation outside it is outlier\n",
    "\n",
    "#### z-score\n",
    "* |Z -score | > 3 is outlier\n",
    "* Not good for small sample. SD can be inflated by single value, less extreme outlier go unnoticed\n",
    "\n",
    "#### modified z-score\n",
    "* To overcome extreme value problem, median and deviation from median is used in modified z-score.\n",
    "\n",
    "#### Box plot\n",
    "* points outside  q1 - (1.5 IQR) or q3  + (1.5 IQR)\n",
    "\n",
    "#### Median absolute deviation\n",
    "* 2 MAD = median +- 2MAD\n",
    "* 3 MAD = median +- 3MAD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile plot\n",
    "* Display all the data, plots quantile info.\n",
    "* For data $x_i$ data sorted in increasing order, $f_i$ indicates that approximately 100*$f_i$ % of the data are below or equal to $x_i$.\n",
    "* 5 Quantile means 5% data less or equal to that value\n",
    "![](images/quanitle_plot.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile - Quantile plot (Q-Q plot)\n",
    "* graph quantile of 1 univariate distribution against other. Is there any shift going on from 1 variable to other. If 2 distribution are similar then y = x.\n",
    "* If we have assumption that given data is normally distributed then we can plot Normal Q-Q plot to check our assumption\n",
    "* It is scatter plot created by plotting 2 set of quantiles against each other. If both quantiles from same distribution then line will be straight.\n",
    "* Quantiles are basically just your data sorted in ascending order, with various data points labelled as being the point below which a certain proportion of the data fall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "* Quantify strength of the relationship between 2 variables. Requirement is both variable should be in same units. Transform each value to standard score (number of SD away from mean) it leads to pearson product moment correlation coefficient. For normal distribution. OR transform each variable to its rank [index is sorted list of values] spearson rank correlation coefficient for non normal distributions\n",
    "\n",
    "### Covariance\n",
    "* Measure of the tendency of 2 variables to vary together. \n",
    "* 2 variable X and Y\n",
    "* dxi = xi - mean of x\n",
    "* dyi = yi - mean of y. Which are deviation of mean. If x and y vary together their distribution will have the same sign.\n",
    "$$COV(x,y) = \\frac{1}{n}\\sum (dxi)(dyi)$$\n",
    "* Dot product of deviation divided by length.\n",
    "* So it is maximized when both are identical and 0 if orthogonal, negative if point in opposite direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cov = np.dot(xs - mean_x, ys - mean_y) / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.cov() returns covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation coefficient\n",
    "* Covariance unit is product of unit of x and y. Divide the deviation by standard deviation, which gives standard score.\n",
    "\n",
    "= $\\frac{COV(x,y)}{S_x S_y}$\n",
    "* Between -1 and 1 indicate strength and sign of association between 2 variable. Sign is same as sign of association. closer to 1 or -1 means stronger association."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/pearson_correlation.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In second row, we can see that correlation does not take look for slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "corf, p = stats.personr(df['colA'], df['colB'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pearson correlation  is normalization of covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* np.cov(x,y) and np.corrcoef(x,y) returns covariance anc pearson correlation matrix respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spearman's Rank correlation\n",
    "* Pearson work for normal and linear. It is not robust for outlier. \n",
    "* Compute rank of given values\n",
    "```\n",
    "xs.corr(ys, method = 'spearman') # xs, ys is pandas series\n",
    "```\n",
    "\n",
    "* If relation is not linear, pearson under estimate strength of relation ( row 3 in above image). Pearson affected if on of the distribution id not normal and has outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To remove effect of skewness we can compute pearson correlation with log normal of x and y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Saturation is loss of information, multiple points are plotted on top of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator\n",
    "#### Maximum likelihood estimator.\n",
    "* Estimate underlying probability with given data\n",
    "* 1 is head, 0 is tail. 100101 is outcome P(H) = 0.5\n",
    "* 11011 P(H) = 0.8\n",
    "* 00000000 P(H) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* x1, x2, x3, ...., xn so, maximum likelihood estimator is 1/N$\\sum xi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We take sum of outcome and normalize with total outcome. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given data is 1,6,6,3,2,6,5,4,6,2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* P(1) = 1/10, P(2) = 2/10 P(3) = 1/10, P(4) = 1/10, P(5) = 1/10, P(6) = 4/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Suppose we have data of single coin flip, MLE will always assume it is loaded and assign probability 1. Solution is to add fake data like\n",
    "    - Data is given 1 => p(1) = 1\n",
    "    - add fake data 1,[1,0] P(H) = 2/3 = 0.667\n",
    "    - Eventually fake data will pull Probability of H towards 0.5\n",
    "    - Estimation after adding fake data is called Laplacian estimator. When few sample available use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
